{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "#gr()\n",
    "pyplot()\n",
    "#plotly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Data Table choices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning is all about finding patterns in data, so it is very reasonble to start with data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 10.1\n",
       " 19.9\n",
       " 30.1\n",
       " 40.3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some Data (try your own)\n",
    "x = [5,6.5,7,8]\n",
    "y = [10.1, 19.9, 30.1, 40.3]\n",
    "# plot(x,y,\n",
    "#     label=\"Y\", line=(7,:green), marker=(10,0.8,:red), xlims=(0,10), ylims=(0,50),\n",
    "#     xlabel=\"X\",ylabel=\"Y\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.1. Just a matrix please. (No labels, no extras, simple.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [x y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2. Data Frames: Inspired by the R universe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "data2 = DataFrame(X=x,Y=y) # Upper Case X and Y are labels (not data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"CSV\")\n",
    "using CSV\n",
    "CSV.write(\"data.csv\", data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ";cat data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.3. Indexed Tables (Treat data like array indices, knows type information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pkg.add(\"IndexedTables\")\n",
    "using  IndexedTables.Table\n",
    "using IndexedTables\n",
    "data3 = Table(Columns(X=x),Columns(Y=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data3[6.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof.([data1,data2,data3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.4. JuliaDB (Lots of bells and whistles, many files, parallelism, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"JuliaDB\")\n",
    "using JuliaDB:DTable\n",
    "using JuliaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data4 = distribute(data3, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data5 = loadfiles([\"data.csv\"], usecache=false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(data4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data4[1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select(data4,1=>i->i≥7) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter(t->(t[1]>30),data4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.5 IterableTables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#using IterableTables, DataTables, TypedTables # haven't investigated  much but looks very nice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Simple Line Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[So why is it called \"Regression\" anyway?](http://blog.minitab.com/blog/statistics-and-quality-data-analysis/so-why-is-it-called-regression-anyway) Dalton's original meaning not quite what it means today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.1 Linear Regression function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b, w =  linreg(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot()\n",
    "plot(x,y,\n",
    "    label=\"Y\", line=(4,:blue), marker=(3,0.8,:blue), xlims=(0,10), ylims=(0,50),\n",
    "    xlabel=\"X\",ylabel=\"Y\")\n",
    "plot!(x->w*x+b,xlims=(minimum(x)-.5,maximum(x)+.5), line=(4,:red), label=\"best fit line\")\n",
    "plot!(x->w*x+b, x ,marker=(3,0.8,:red), label=\"\" )\n",
    "for i = 1:length(x)\n",
    "    plot!([x[i],x[i]],[y[i],w*x[i]+b],line=(4,:green))\n",
    "end\n",
    "plot!(legend=:topleft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically equivalent Approaches <br>\n",
    "B.2 Linear Algebra Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [ones(x) x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A'A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A\\y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(A'A)\\A'y  # normal equations usually not recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q,r = qr(A)\n",
    "r\\(q'y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[length(x) sum(x); sum(x) x⋅x] \\ [ sum(y) ; x⋅y ] # (A'A)\\A'y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.3 Basic Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = cov(x,y)/var(x) # same as (x.-mean(x))⋅(y.-mean(y))/sum(abs2,x.-mean(x))\n",
    "b = mean(y)-w*mean(x)\n",
    "b,w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@which linreg(x,y) # essentially uses the above formula"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.4 optimization  (think machine learning) via the package optim.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Optim   # Julia all the way down\n",
    "loss(bw) = sum(abs2,bw[2]*x.+bw[1]-y) # uglyish\n",
    "optimize(loss,[0.0,0.0]).minimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.5 optimization with the package JuMP <br>\n",
    "Note not every julia function can be in @objective or @NLobjective\n",
    "but that would be the goal. See  [linear and quadratic objective Jump Notes](http://www.juliaopt.org/JuMP.jl/0.18/refexpr.html)  and [Nonlinear Jump Notes](http://www.juliaopt.org/JuMP.jl/0.18/nlp.html#syntax-notes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"Ipopt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using JuMP, Ipopt\n",
    "n = length(x)\n",
    "m = Model(solver=IpoptSolver(print_level=0))\n",
    "@variable(m,w)\n",
    "@variable(m,b)\n",
    "@objective(m, Min, sum((w*x[i]+b-y[i])^2 for i in 1:n))\n",
    "#@objective(m, Min,   sum(abs2,  w*x+b-y))\n",
    "solve(m)\n",
    "println( \" b = \", getvalue(b), \"w = \", getvalue(w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B.6 Generalized Linear Models <br>\n",
    "the very fancy statistical thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"GLM\")\n",
    "using GLM # Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(@formula(Y~X), data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines above are obviously b and w\n",
    "We assume at the start X is known without error, b,w,σ are unknown and\n",
    "the real Y is distributed like  b+w*X+$\\sigma *$randn(),\n",
    "and the Y we have are samples from this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under these assumptions, if we fit many times, the b and w would be normal, with these predicted standard deviations.\n",
    "\n",
    "The third column is just the ratio of column 1 to column 2 , thus normalizing the situation to a standard normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the probability column is less than .05, we can reject the hypothesis that the intercept/slope is 0 at the 5 percent signficance level. What does this mean? It means we feel pretty good about our intercept and slope. If the probability is higher than .05 we can not reject the null hypothesis, meaning that we feel 0 for the intercept/slope could have been possible. In particular a 0 slope says that the dependent variable is not really statistically dependent after all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(w,b,i) =(w*x[i]+b-y[i])^2  # loss due to point i\n",
    "Dloss(w,b,i) = 2*(w*x[i]+b-y[i])*[x[i];1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,b = 0.0, 0.0\n",
    "for t=1:100000\n",
    "    η = .002  # there seems to be an art to picking these steplengths\n",
    "    i = rand(1:4)\n",
    "    d = Dloss(w,b,i)\n",
    "    w -= η * d[1]\n",
    "    b -= η * d[2]  \n",
    "end\n",
    " println(b,\" \",w)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(w,b,i) =(w*χ[i]+b-y[i])^2  # loss due to point i\n",
    "Dloss(w,b,i) = 2*(w*χ[i]+b-y[i])*[χ[i];1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "μ = mean(x)\n",
    "σ = std(x)\n",
    "χ = (x-μ)/σ\n",
    "\n",
    "w,b = 0.0, 0.0\n",
    "for t=1:100000\n",
    "    η = .01  # there seems to be an art to picking these steplengths\n",
    "    i = rand(1:4)\n",
    "    d = Dloss(w,b,i)\n",
    "     w -= η * d[1]\n",
    "     b -= η * d[2] \n",
    "    ## instead fancy update rules like Adam ??\n",
    "   \n",
    "end\n",
    " println(b-w*μ/σ,\" \",w/σ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  D. KNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"Knet\")\n",
    "using Knet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(w,x) = w[2]*x .+ w[1]\n",
    "loss(w,x,y) = sum(abs2, y - predict(w,x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossgradient = grad(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train(w, data; lr=.1)\n",
    "    p=1\n",
    "    for (x,y) in data\n",
    "        println(\"This is pass $p\")\n",
    "        p+=1\n",
    "        dw = lossgradient(w, x, y)\n",
    "        for i in 1:length(w)\n",
    "            w[i] -= lr * dw[i]\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train([0.0,0.0],zip(x,y),lr=.01) # not enough data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(x[i],y[i]) for i=1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train2(w, data; lr=.1)\n",
    "       for t in 1:10000\n",
    "          \n",
    "        (x,y) = data[rand(1:4)]\n",
    "        dw = lossgradient(w, x, y)\n",
    "            for i=1:length(w)\n",
    "            w[i] -= lr * dw[i]\n",
    "            #update(w, lossgradient(w,x,y), adam())\n",
    "        end\n",
    "    end\n",
    "    return w\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2([0.0;0.0],data,lr=.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPrecompiling module TensorFlow.\n",
      "\u001b[39m\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mLoading a new version of TensorFlow.jl for the first time. This initial load can take around 5 minutes as code is precompiled; subsequent usage will only take a few seconds.\u001b[39m\n",
      "WARNING: Base.FloatRange is deprecated, use Base.Use_StepRangeLen_Instead{T} where T<:AbstractFloat instead.\n",
      "  likely near /Users/edelman/.julia/v0.6/TensorFlow/src/ops/indexing.jl:102\n",
      "2017-10-01 12:37:03.787744: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-10-01 12:37:03.787774: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Session(Ptr{Void} @0x000000011bc72ef0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pkg.add(\"TensorFlow\")\n",
    "using TensorFlow\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorFlow.Variables.Variable{Float64}(<Tensor node_2:1 shape=() dtype=Float64>, <Tensor node_2/Assign:1 shape=unknown dtype=Float64>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = TensorFlow.Variable(randn())\n",
    "b = TensorFlow.Variable(randn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33m.+ is no longer a function object; use broadcast(+, ...) instead\u001b[39m\n",
      "Stacktrace:\n",
      " [1] \u001b[1mdepwarn\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::Symbol\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:70\u001b[22m\u001b[22m\n",
      " [2] \u001b[1m(::Base.##712#713)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Tensor{Float64}, ::TensorFlow.Variables.Variable{Float64}\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./deprecated.jl:346\u001b[22m\u001b[22m\n",
      " [3] \u001b[1m(::TensorFlow.###8#9#11{Base.##712#713})\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Array{Any,1}, ::Function, ::TensorFlow.Tensor{Float64}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/TensorFlow/src/meta.jl:67\u001b[22m\u001b[22m\n",
      " [4] \u001b[1m(::TensorFlow.##8#10)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::TensorFlow.Tensor{Float64}, ::Vararg{Any,N} where N\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/TensorFlow/src/meta.jl:67\u001b[22m\u001b[22m\n",
      " [5] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./loading.jl:515\u001b[22m\u001b[22m\n",
      " [6] \u001b[1minclude_string\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::Module, ::String, ::String\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/Compat/src/Compat.jl:464\u001b[22m\u001b[22m\n",
      " [7] \u001b[1mexecute_request\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket, ::IJulia.Msg\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/IJulia/src/execute_request.jl:154\u001b[22m\u001b[22m\n",
      " [8] \u001b[1meventloop\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m::ZMQ.Socket\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m/Users/edelman/.julia/v0.6/IJulia/src/eventloop.jl:8\u001b[22m\u001b[22m\n",
      " [9] \u001b[1m(::IJulia.##14#17)\u001b[22m\u001b[22m\u001b[1m(\u001b[22m\u001b[22m\u001b[1m)\u001b[22m\u001b[22m at \u001b[1m./task.jl:335\u001b[22m\u001b[22m\n",
      "while loading In[4], in expression starting on line 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Tensor Y_obs:1 shape=unknown dtype=Float32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf X = placeholder(Float32)\n",
    "@tf Y = multiply(X,W).+b\n",
    "@tf Y_obs = placeholder(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor reduce:1 shape=unknown dtype=Float64>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf Loss=sum( (Y.-Y_obs).^2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Tensor Group:1 shape=unknown dtype=Any>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = TensorFlow.train.GradientDescentOptimizer(1e-3)\n",
    "minimizer = TensorFlow.train.minimize(optimizer, Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(session, global_variables_initializer())\n",
    "for i in 1:20000\n",
    "    run(session, minimizer, Dict(X=>x, Y_obs=>y))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{Float64,1}:\n",
       " -41.7434\n",
       "  10.0923"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(session, [b, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session=Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf X=placeholder(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf W=get_variable([], Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@tf b=get_variable([], Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf Y=X.*W + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf Y_obs=placeholder(Float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf Loss=reduce_sum((Y.-Y_obs).^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=train.GradientDescentOptimizer(1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimizer=train.minimize(optimizer, Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(session, global_variables_initializer())\n",
    "for i in 1:20000\n",
    "    run(session, minimizer, Dict(X=>[5,6.5,7,8], Y_obs=>[10.1,19.9,30.1,40.3]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run(session, [b, W])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.0",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
